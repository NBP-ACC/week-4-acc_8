{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osnabrück University - A&C: Computational Cognition (Summer Term 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 02: Basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in at 14:00 at **Tuesday, April 30, 2019**. If you need help (and Google and other resources were not enough), feel free to contact your tutors. Please push your results to your Github group folder.\n",
    "\n",
    "In this exercise sheet you will have to work with ```pandas``` and ```seaborn```. ```pandas``` is one of the most preferred and widely used tools in data processing. What’s cool about ```pandas``` is that it takes data (like a CSV or TSV file, or a SQL database) and creates a Python object with rows and columns called 'data frame' that looks very similar to tables in a statistical software (think Excel or SPSS for example). ```pandas``` makes data processing a lot easier in comparison to working with lists and/or dictionaries through for-loops or list comprehension.  \n",
    "```seaborn``` is a library for making plots. It is based on ```matplotlib``` but offers more functions speicialized for statistical visualization. Also most people agree that ```seaborn``` looks more legit.\n",
    "\n",
    "Don't forget that you we will also give **2 points** for nice coding style!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 0: Peer review for sheet 01 [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning this week you will have to make a peer review of the other groups' solutions. Each group reviews the solutions of two other groups and give points according to the given point distribution considering the correctness of the solution. For this reviews the tutors will give you up to 3 points each week.\n",
    "\n",
    "| * |Group 1|Group 2|Group 3|Group 4|Group 5|Group 6|Group 7|Group 8|Group 9|Group 10|Group 11|\n",
    "| ------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------ | ------ |\n",
    "| check solutions of group: | 10, 7 | 4, 9  | 1, 4  | 11, 1 | 8, 11 | 5, 3  | 9, 10 | 6, 5  | 3, 2  | 2, 8   | 7, 6   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should open an issue in repositories of groups you have to check. The title of the issue should be your group name (e.g.\"Group 1\"). Comments on what was good and bad, how much points they get etc.  \n",
    "Refer to https://guides.github.com/features/issues/ to learn more about issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Dataframes [4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```matplotlib``` and ```seaborn``` should already be installed in your environment. If not please run:\n",
    "```sh\n",
    "pip install seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Importing a csv file [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the csv files of all subjects into one dataframe. Make sure that each row has a unique index. You might want to take a look at what ***pandas.concat*** does.<br>\n",
    "Extra fun: Display the output of the dataframe using the ***pandas.set_option*** function to display the data in a well-arranged way. Play a little bit around with the settings that you are allowed to change.<br>\n",
    "Save ```df_concatenated```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "PATH = os.getcwd()+ \"/Data\"\n",
    "\n",
    "all_files = glob.glob(os.path.join(PATH, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "                                                       # http://www.oipapio.com/question-88634    \n",
    "\n",
    "# use pd.set_option here to display in a nice way\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files) \n",
    "df_concatenated = pd.concat(df_from_each_file, ignore_index=True) # combines all dataframes and creates new dataframe\n",
    "df_concatenated\n",
    "# save concatenated dataframe\n",
    "DATAPATH = os.getcwd() + '/Processed/data_concatenated.csv'\n",
    "\n",
    "df_concatenated.to_csv(DATAPATH, index=False) # write concatenated to a csv in the Processed folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Working with dataframes [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a column called \"congruence\" to ```df_concatenated```. The column should have a value *True* if \"StimulusType\" and \"reponse\" matches. Otherwise the column should have a value *False*.\n",
    "\n",
    "- Create a new dataframe which has \"SubjectID\",\"StiumulusType\",\"RT\" and \"congruence\" as a column. For each combination of \"SubjectID\" and \"StimulusType\" (e.g. \"7001\" and \"0\") compute the average RT and congruence level.\n",
    "\n",
    "- When computing the average RT, omit all reaction times which are 0 as these will manipulate the mean.\n",
    "\n",
    "- Rename \"congruence\" as \"accuracy\" and save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubjectID  StimulusType\n",
      "8001       0                90.6000\n",
      "           1               342.2125\n",
      "8002       0                49.2000\n",
      "           1               357.7625\n",
      "8003       0                 0.0000\n",
      "           1               435.1625\n",
      "8004       0                32.1500\n",
      "           1               340.2125\n",
      "8005       0                99.7500\n",
      "           1               321.7500\n",
      "8006       0                74.4500\n",
      "           1               328.9625\n",
      "8007       0                30.4500\n",
      "           1               355.3875\n",
      "8008       0                 0.0000\n",
      "           1               358.2000\n",
      "Name: RT, dtype: float64\n",
      "SubjectID  StimulusType\n",
      "8001       0               0.7000\n",
      "           1               1.0000\n",
      "8002       0               0.8500\n",
      "           1               1.0000\n",
      "8003       0               1.0000\n",
      "           1               1.0000\n",
      "8004       0               0.9000\n",
      "           1               0.9875\n",
      "8005       0               0.7000\n",
      "           1               1.0000\n",
      "8006       0               0.7500\n",
      "           1               1.0000\n",
      "8007       0               0.9000\n",
      "           1               1.0000\n",
      "8008       0               1.0000\n",
      "           1               1.0000\n",
      "Name: congruence, dtype: float64\n",
      "     SubjectID  StimulusType   RT  accuracy\n",
      "0         8001             1  781      True\n",
      "1         8001             0    0      True\n",
      "2         8001             1  345      True\n",
      "3         8001             1  495      True\n",
      "4         8001             1  420      True\n",
      "5         8001             0    0      True\n",
      "6         8001             1  332      True\n",
      "7         8001             1  365      True\n",
      "8         8001             1  410      True\n",
      "9         8001             1  306      True\n",
      "10        8001             1  374      True\n",
      "11        8001             1  327      True\n",
      "12        8001             1  399      True\n",
      "13        8001             1  337      True\n",
      "14        8001             0    0      True\n",
      "15        8001             1  297      True\n",
      "16        8001             1  297      True\n",
      "17        8001             1  299      True\n",
      "18        8001             0    0      True\n",
      "19        8001             1  347      True\n",
      "20        8001             1  345      True\n",
      "21        8001             0    0      True\n",
      "22        8001             0    0      True\n",
      "23        8001             1  354      True\n",
      "24        8001             1  295      True\n",
      "25        8001             1  280      True\n",
      "26        8001             1  296      True\n",
      "27        8001             1  315      True\n",
      "28        8001             0  335     False\n",
      "29        8001             1  340      True\n",
      "..         ...           ...  ...       ...\n",
      "770       8008             1  320      True\n",
      "771       8008             1  336      True\n",
      "772       8008             1  288      True\n",
      "773       8008             1  337      True\n",
      "774       8008             0    0      True\n",
      "775       8008             1  304      True\n",
      "776       8008             1  400      True\n",
      "777       8008             1  352      True\n",
      "778       8008             1  336      True\n",
      "779       8008             1  448      True\n",
      "780       8008             1  337      True\n",
      "781       8008             1  336      True\n",
      "782       8008             0    0      True\n",
      "783       8008             1  321      True\n",
      "784       8008             1  320      True\n",
      "785       8008             1  304      True\n",
      "786       8008             1  336      True\n",
      "787       8008             1  352      True\n",
      "788       8008             1  401      True\n",
      "789       8008             1  432      True\n",
      "790       8008             1  384      True\n",
      "791       8008             1  368      True\n",
      "792       8008             1  336      True\n",
      "793       8008             1  432      True\n",
      "794       8008             1  353      True\n",
      "795       8008             0    0      True\n",
      "796       8008             1  352      True\n",
      "797       8008             0    0      True\n",
      "798       8008             1  320      True\n",
      "799       8008             1  369      True\n",
      "\n",
      "[800 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# add a column \"congruence\"\n",
    "# TODO\n",
    "#csv_input = pd.read_csv('Processed/data_concatenated.csv')\n",
    "#csv_input['congruence'] = np.where(csv_input['StimulusType']==csv_input['response'], True, False)\n",
    "#csv_input.to_csv('Processed/data_concatenated.csv', index=False)\n",
    "df_concatenated['congruence'] = \"\" # creates an empty column called 'congruence'\n",
    "# assigns value True to congruence column if StimulusType and response are matching, assigns False if not matching\n",
    "df_concatenated['congruence'] = np.where(df_concatenated['StimulusType']==df_concatenated['response'], True, False)\n",
    "\n",
    "\n",
    "# create a new dataframe with averaged data\n",
    "#df_concatenated_avg = pd.DataFrame(columns=['SubjectID', 'StimulusType', 'avRT', 'AVсongruence'])\n",
    "#df_concatenated_avg = pd.read_csv('Processed/data_concatenated.csv')\n",
    "#df_concatenated_avg['RT']=df_concatenated_avg.groupby('SubjectID').mean()\n",
    "df_concatenated_avg = df_concatenated.copy() # creates a deep copy of old data frame\n",
    "df_concatenated_avg = df_concatenated_avg.drop(columns=['response']) # deletes the column 'response'\n",
    "# calculates the mean RT while omitting 0 values for different combinations of SubjectID and StimulusType \n",
    "average_RT = df_concatenated_avg.groupby(['SubjectID', 'StimulusType'])['RT'].mean() \n",
    "print(average_RT)\n",
    "# calculates the mean congruence for different combinations of SubjectID and StimulusType\n",
    "average_congruence = df_concatenated_avg.groupby(['SubjectID', 'StimulusType'])['congruence'].mean()\n",
    "print(average_congruence)\n",
    "\n",
    "# changes the name of the 'congruence' column to 'accuracy'\n",
    "df_concatenated_avg = df_concatenated_avg.rename(columns={'congruence':'accuracy'})\n",
    "\n",
    "# TODO\n",
    "# saves averaged dataframe as a csv file\n",
    "DATAPATH = os.getcwd() + '/Processed/data_concatenated_averaged.csv'\n",
    "df_concatenated_avg.to_csv(DATAPATH, index=False)\n",
    "# TODO\n",
    "print(df_concatenated_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Statistical plotting [6 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Boxplot and Violinplot [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the RT of each trial for all subjects as a stripplot and a boxplot on top of each other. Do the same with a striplot and a violinplot. Plot go trials as green dots and no-go trails as red dots. Reminder: don't forget to mask the data where RT=0. Make sure that the legends are informative (Don't display duplicated legends)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "data_concat = pd.read_csv(os.getcwd() + \"/Processed/data_concatenated.csv\")\n",
    "\n",
    "# create two axes\n",
    "fig, axes = plt.subplots(nrows=1,ncols=2)\n",
    "\n",
    "# first subplot with stripplot and boxplot\n",
    "# TODO \n",
    "\n",
    "# second subplot with stripplot and violinplot\n",
    "# TODO\n",
    "\n",
    "# handling legends\n",
    "# TODO\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Violinplot combining all data of all groups [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a dataframe consisting of all data across groups. You already did this in 1.a). At the end this dataframe you should have 8 * 11 * 100 rows.\n",
    "\n",
    "- Every group has used their ID convention. Make sure that every data point follows this SubjectID system: group number + \"00\" + subject number.  \n",
    "e.g) 3002 for the second subject of the third group.\n",
    "\n",
    "- Compute average RT and accuaracy for each subject in the big dataframe you just created. You already did this in 1.b). At the end this dataframe will have 8 * 11 rows.\n",
    "\n",
    "- On the first column plot average RT and accuracy for 8 subjects from your group's data. Use violinplot and split go/no-go conditions.\n",
    "\n",
    "- On the second column plot average RT and accuracy for 80 subjects from all data. Use violinplot and split go/no-go conditions.\n",
    "\n",
    "- Do you see any difference between the first column and the second column? What does this tell us about the central limit theorem (CLT) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again create a concatenated dataframe over all (averaged) groups.\n",
    "# Don't forget to modify the Subject ID\n",
    "# TODO\n",
    "\n",
    "# Now it's time to plot your results\n",
    "figs, axes = plt.subplots(nrows=2, ncols=2, sharey=\"row\")\n",
    "\n",
    "# violin plot for your group's data\n",
    "# TODO\n",
    "\n",
    "# violin plot of all group's data\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two datasets and relate it with CLT. Write your opinion here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Scatterplot [1 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatterplot comparing RT and accuracy. Do you see some correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
